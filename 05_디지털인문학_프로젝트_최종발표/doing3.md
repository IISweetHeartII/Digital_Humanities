# 디지털 인문학 프로젝트 진행 과정 요약 (doing3.md)

## 1. 프로젝트 초기 목표 및 계획

- **최종 목표**: 철학자들의 네트워크 중심성 지표를 분석하여 지적 영향력을 평가하고, 다각적인 비교 분석을 통해 깊이 있는 해석을 담은 최종 보고서(`doing2.md`)를 완성하는 것.
- **초기 계획**:
  1. `top_50_centralities_standard.csv`에서 '내차수 중심성(In-Degree Centrality)' 기준 상위 50명을 필터링.
  2. 철학자의 활동 시기를 반영한 '시간 보정 내차수 중심성(Adjusted In-Degree Centrality)'을 계산.
  3. '표준 순위', '시간 보정 순위', 그리고 'AI(ChatGPT, Gemini) 추천 순위'를 상호 비교.
  4. 분석 결과를 종합하여 최종 보고서를 작성.

## 2. 데이터 분석 과정에서 마주한 난관 및 해결 과정

프로젝트는 여러 기술적, 논리적 문제에 부딪혔으며, 이를 해결하는 과정은 다음과 같았습니다.

### 2.1. 1단계: 초기 스크립트 실행 오류

- **문제점**: Python 스크립트 실행 시, 파일 경로 및 작업 디렉토리 불일치로 인해 `FileNotFoundError`가 반복적으로 발생.
- **해결 과정**:
  - `os.path.join`을 사용하여 OS에 맞는 파일 경로를 구성하도록 코드를 수정.
  - `cd` 명령어를 통해 스크립트가 위치한 `05_디지털인문학_프로젝트_최종발표` 디렉토리로 이동하여 실행 환경을 통일.

### 2.2. 2단계: 시간 보정 중심성 계산 오류

- **문제점**: `08_calculate_adjusted_centrality.py` 실행 후, '시간 보정 중심성' 결과가 모두 `NaN` (Not a Number)으로 계산되는 심각한 논리적 오류 발생.
- **원인 분석**: 디버깅을 통해, 철학자의 활동 연대 데이터(`philosophers_by_century.csv`)를 `data/raw/`가 아닌, 잘못된 경로에서 읽어오고 있었음을 발견.
- **해결 과정**:
  1. `08_calculate_adjusted_centrality.py` 스크립트의 파일 경로를 올바른 원본 데이터 경로로 수정.
  2. 수정 후에도 문제가 지속되는 듯하여, 파일 캐싱이나 환경 문제를 의심. 이를 회피하기 위해 `temp_fix_08.py`라는 새로운 임시 스크립트를 생성하여 정확한 로직을 다시 구현.
  3. `temp_fix_08.py` 실행 중, `philosophers_by_century.csv` 파일에서 `UnicodeDecodeError` 발생.
  4. 파일 인코딩 문제를 해결하기 위해 `utf-8`, `latin1`, `cp1252` 등 다양한 인코딩을 순차적으로 시도하는 파일 로드 함수를 구현하여 문제를 최종 해결.
  5. 성공적으로 '시간 보정 중심성' 값을 계산하고 `adjusted_centralities.csv` 파일을 생성.

### 2.3. 3단계: 이름 표준화 문제와의 사투

- **문제점**: 모든 분석 파이프라인을 실행한 후, 최종 비교 파일(`rankings_comparison_... .csv`)들에서 두 목록 간의 공통 철학자가 거의 없는 문제 발견.
- **원인 분석**: 데이터 소스(중심성 데이터, AI 추천 목록) 간에 철학자 이름 표기법이 달라 동일 인물로 인식되지 않음.
  - **예시**: `T. Aquinas` vs. `Thomas Aquinas`, `F. Nietzsche` vs. `Friedrich Nietzsche`, 한글 이름 vs. 영문 이름 등.
- **해결 과정**:
  1. **1차 시도**: `10_compare_centrality_rankings.py`에 이름 변환 딕셔너리(`name_map`)를 추가하여 이름 표준화 함수(`clean_ai_name`)를 구현. 하지만 일부 이니셜과 케이스를 처리하지 못해 실패.
  2. **2차 시도**: `name_map`을 확장하고 정규표현식을 활용하는 등 로직을 개선했으나, 함수 적용 순서의 문제로 여전히 일부 이름이 변환되지 않음.
  3. **최종 해결**: 문제의 근본 원인이 복잡하게 얽힌 함수 호출 순서에 있다고 판단, **`temp_fix_10.py`** 라는 새로운 임시 스크립트를 작성. 이 스크립트는 **(1) 모든 데이터를 먼저 로드 → (2) 가장 포괄적인 `name_map`을 사용하여 모든 데이터의 이름을 최우선으로 표준화 → (3) 이후에 순위 매기기 및 비교 분석 수행**이라는 명확하고 단순한 파이프라인으로 재설계됨.
  4. 이 새로운 스크립트를 실행하여 마침내 모든 이름이 완벽하게 통일된 5개의 최종 비교 파일을 성공적으로 생성.

## 3. 최종 성과

- 모든 기술적, 논리적 오류를 해결하고 데이터 분석 파이프라인을 성공적으로 완주.
- '표준 중심성', '시간 보정 중심성', 'AI 추천 목록' 간의 의미 있는 비교 분석이 가능한 최종 데이터셋 구축 완료.
- 정확한 분석 결과를 바탕으로 프로젝트의 결론을 도출하고, 최종 보고서 `doing2.md`를 성공적으로 업데이트.

이 과정을 통해, 단순 코딩 문제를 넘어 데이터 정합성, 인코딩, 논리 흐름의 중요성을 깊이 체감하며 디지털 인문학 프로젝트를 성공적으로 완수했습니다.
